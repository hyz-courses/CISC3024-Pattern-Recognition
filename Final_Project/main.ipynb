{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea06134c-8d90-41fe-8b10-903b583fedfb",
   "metadata": {},
   "source": [
    "# CISC3024 Pattern Recognition Final Project\n",
    "## Group Members:\n",
    "- Huang Yanzhen, DC126732\n",
    "- Mai Jiajun, DC12785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01653d-682d-42cd-a3e9-81c26622b8c0",
   "metadata": {},
   "source": [
    "## 0. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42857a-bbdb-4f57-afae-b08ec4c32147",
   "metadata": {},
   "source": [
    "### 0.1 Packages & Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "701b0ee5-3106-4d3f-bf0e-c511feb4a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0be3ed78-d627-4715-90b8-fd957e77d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "print(f\"Using device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe520b-0991-4f87-9782-49bf7d9f0a7d",
   "metadata": {},
   "source": [
    "### 0.2 Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffc666c2-ec1a-4b59-9e1f-997f27c72dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"./data/SVHN_mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca60f72-83da-4a78-bc7b-d2e14a0d15a7",
   "metadata": {},
   "source": [
    "## 1. Data Processing and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e8db9-06ca-4b0a-be31-e4e4a4e0531b",
   "metadata": {},
   "source": [
    "### 1.1 Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22332722-fc5b-42e9-bedf-64006c4784b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad57aecf-ec6d-4039-aead-0886a9aca224",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomResizedCrop(32, 32),\n",
    "    A.Rotate(limit=30),\n",
    "    A.Normalize(mean=[0.4377, 0.4438, 0.4728], std=[0.1980, 0.2010, 0.1970]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d279dbc-5ee7-4562-89c6-5a2452d2d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, mat_file, transform=None):\n",
    "        data = sio.loadmat(mat_file)\n",
    "        self.images = np.transpose(data['X'], (3, 0, 1, 2))\n",
    "        self.labels = data['y'].flatten()\n",
    "        self.labels[self.labels == 10] = 0\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2fe21d2-e40e-4016-8dcc-dff286b49d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SVHNDataset(mat_file=os.path.join(path_dataset,\"train_32x32.mat\"), transform=transform)\n",
    "test_dataset = SVHNDataset(mat_file=os.path.join(path_dataset,\"test_32x32.mat\"), transform=transform)\n",
    "extra_dataset = SVHNDataset(mat_file=os.path.join(path_dataset,\"extra_32x32.mat\"), transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f50b603-13f9-4220-9d32-57d5078599b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'You have to pass data to augmentations as named arguments, for example: aug(image=image)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m, in \u001b[0;36mSVHNDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 17\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32mE:\\Courses\\CISC3024-Pattern-Recognition\\cisc3024_pr_venv\\lib\\site-packages\\albumentations\\core\\composition.py:333\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m    332\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to pass data to augmentations as named arguments, for example: aug(image=image)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(force_apply, (\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m    336\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_apply must have bool or int type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)'"
     ]
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d332d40-7a38-4a83-8c6d-ed1c32a99bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
